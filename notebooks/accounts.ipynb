{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import boto3\n",
    "import os\n",
    "import logging\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# AWS credentials\n",
    "AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_REGION = os.getenv('AWS_REGION', 'us-east-1')\n",
    "BUCKET_NAME = \"census-warpcast-account-metadata\"\n",
    "\n",
    "# Neo4j credentials\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\", None)\n",
    "\n",
    "\n",
    "# Set up S3 clients\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    region_name=AWS_REGION,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    region_name=AWS_REGION,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "def sanitize_text(text):\n",
    "    \"\"\"\n",
    "    Sanitize text to make it suitable for Neo4j queries by removing special characters\n",
    "    and escaping quotes.\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return \"\"\n",
    "        \n",
    "    # Replace quotes and escape characters\n",
    "    sanitized = text.replace(\"'\", \"\\\\'\").replace('\\\\', '\\\\\\\\')\n",
    "    \n",
    "    # Remove control characters\n",
    "    sanitized = re.sub(r'[\\x00-\\x1F\\x7F]', '', sanitized)\n",
    "    \n",
    "    return sanitized\n",
    "\n",
    "\n",
    "# Function to convert string boolean values to actual booleans\n",
    "def str2bool(value):\n",
    "    \"\"\"\n",
    "    Convert string representations of boolean values to actual booleans.\n",
    "    \"\"\"\n",
    "    if isinstance(value, bool):\n",
    "        return value\n",
    "    if not value or not isinstance(value, str):\n",
    "        return False\n",
    "    return value.lower() in ('true', 't', 'yes', 'y', '1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Neo4j driver\n",
    "neo4j_driver = GraphDatabase.driver(\n",
    "    NEO4J_URI, \n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    ")\n",
    "\n",
    "def split_dataframe(df, chunk_size=10000):\n",
    "    \"\"\"Split a DataFrame into chunks\"\"\"\n",
    "    chunks = []\n",
    "    num_chunks = len(df) // chunk_size + (1 if len(df) % chunk_size else 0)\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i * chunk_size:(i + 1) * chunk_size])\n",
    "    return chunks\n",
    "\n",
    "def save_df_as_csv(df, file_name, acl='public-read', max_lines=10000, max_size=10000000):\n",
    "    \"\"\"Save DataFrame to CSV in S3 with chunking if needed\"\"\"\n",
    "    chunks = [df]\n",
    "    \n",
    "    # Check if dataframe needs to be split\n",
    "    if df.memory_usage(index=False).sum() > max_size or len(df) > max_lines:\n",
    "        chunks = split_dataframe(df, chunk_size=max_lines)\n",
    "    \n",
    "    logger.info(f\"Uploading DataFrame in {len(chunks)} chunks...\")\n",
    "    urls = []\n",
    "    \n",
    "    for chunk_id, chunk in enumerate(chunks):\n",
    "        chunk_name = f\"{file_name}--{chunk_id}.csv\"\n",
    "        \n",
    "        # Save to S3 directly using pandas\n",
    "        chunk.to_csv(f\"s3://{BUCKET_NAME}/{chunk_name}\", index=False, escapechar='\\\\')\n",
    "        \n",
    "        # Set ACL\n",
    "        s3_resource.ObjectAcl(BUCKET_NAME, chunk_name).put(ACL=acl)\n",
    "        \n",
    "        # Get URL\n",
    "        location = s3_client.get_bucket_location(Bucket=BUCKET_NAME)[\"LocationConstraint\"]\n",
    "        if location is None:\n",
    "            location = \"us-east-1\"\n",
    "        \n",
    "        url = f\"https://s3-{location}.amazonaws.com/{BUCKET_NAME}/{chunk_name}\"\n",
    "        urls.append(url)\n",
    "        logger.info(f\"Saved chunk {chunk_id+1}/{len(chunks)} to {url}\")\n",
    "    \n",
    "    return urls\n",
    "\n",
    "def get_latest_file(prefix):\n",
    "    \"\"\"Get latest file from S3 bucket with given prefix\"\"\"\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=BUCKET_NAME,\n",
    "        Prefix=prefix\n",
    "    )\n",
    "    \n",
    "    if 'Contents' not in response:\n",
    "        logger.error(f\"No files found with prefix {prefix}\")\n",
    "        return None\n",
    "        \n",
    "    all_files = sorted(response['Contents'], key=lambda x: x['LastModified'], reverse=True)\n",
    "    \n",
    "    if not all_files:\n",
    "        logger.error(f\"No files found with prefix {prefix}\")\n",
    "        return None\n",
    "        \n",
    "    latest_file = all_files[0]['Key']\n",
    "    logger.info(f\"Found latest file: {latest_file}\")\n",
    "    \n",
    "    return latest_file\n",
    "\n",
    "def get_file_content(key):\n",
    "    \"\"\"Get content of file from S3\"\"\"\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=BUCKET_NAME, Key=key)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting S3 file content: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def execute_cypher(query):\n",
    "    \"\"\"Execute a Cypher query in Neo4j\"\"\"\n",
    "    with neo4j_driver.session(database=NEO4J_DATABASE) as session:\n",
    "        result = session.run(query)\n",
    "        return list(result)\n",
    "\n",
    "def create_farcaster_accounts(csv_url):\n",
    "    \"\"\"Create Farcaster accounts in Neo4j\"\"\"\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{csv_url}' AS row\n",
    "    MERGE (account:Account:Warpcast {{fid: row.fid}})\n",
    "    ON CREATE SET\n",
    "        account.uuid = randomUUID(),\n",
    "        account.username = row.username,\n",
    "        account.displayName = row.display_name,\n",
    "        account.bio = row.bio,\n",
    "        account.following_count = toInteger(row.following_count),\n",
    "        account.follower_count = toInteger(row.follower_count),\n",
    "        account.verified = toBoolean(row.verified),\n",
    "        account.pfpUrl = row.pfp_url,\n",
    "        account.profile_image = row.profile_image,\n",
    "        account.power_badge = row.power_badge,\n",
    "        account.mentioned_profiles = row.mentioned_profiles,\n",
    "        account.city = row.city,\n",
    "        account.state = row.state,\n",
    "        account.state_code = row.state_code,\n",
    "        account.country = row.country,\n",
    "        account.country_code = row.country_code,\n",
    "        account.createdDt = tostring(datetime()),\n",
    "        account.lastUpdatedDt = tostring(datetime()),\n",
    "        account.text_content = COALESCE(row.display_name, '') + ' ' + \n",
    "                               COALESCE(row.username, '') + ' ' + \n",
    "                               COALESCE(row.bio, '') + ' ' + \n",
    "                               COALESCE(row.city, '') + ' ' + \n",
    "                               COALESCE(row.state, '') + ' ' + \n",
    "                               COALESCE(row.country, '')\n",
    "    ON MATCH SET\n",
    "        account.username = row.username,\n",
    "        account.displayName = row.display_name,\n",
    "        account.bio = row.bio,\n",
    "        account.following_count = toInteger(row.following_count),\n",
    "        account.follower_count = toInteger(row.follower_count),\n",
    "        account.verified = toBoolean(row.verified),\n",
    "        account.pfp_url = row.pfp_url,\n",
    "        account.profile_image = row.profile_image,\n",
    "        account.power_badge = toBoolean(row.power_badge),\n",
    "        account.mentioned_profiles = row.mentioned_profiles,\n",
    "        account.city = row.city,\n",
    "        account.state = row.state,\n",
    "        account.state_code = row.state_code,\n",
    "        account.country = row.country,\n",
    "        account.country_code = row.country_code,\n",
    "        account.lastUpdatedDt = tostring(datetime()),\n",
    "        account.text_content = COALESCE(row.display_name, '') + ' ' + \n",
    "                               COALESCE(row.username, '') + ' ' + \n",
    "                               COALESCE(row.bio, '') + ' ' + \n",
    "                               COALESCE(row.city, '') + ' ' + \n",
    "                               COALESCE(row.state, '') + ' ' + \n",
    "                               COALESCE(row.country, '')\n",
    "    RETURN count(*)\n",
    "    \"\"\"\n",
    "    result = execute_cypher(query)\n",
    "    count = result[0][0] if result else 0\n",
    "    logger.info(f\"Created/updated {count} Farcaster accounts in Neo4j\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:24:36,110 - __main__ - INFO - Loading Warpcast account data from S3\n",
      "2025-03-28 15:24:37,203 - __main__ - INFO - Found latest file: warpcast/users/20250328_073938_responses.json\n",
      "2025-03-28 15:25:18,414 - __main__ - INFO - Successfully loaded data with 8671 batch responses\n",
      "2025-03-28 15:25:18,415 - __main__ - INFO - Processing Warpcast account data\n",
      "2025-03-28 15:25:18,439 - __main__ - INFO - Processed 10000 users so far\n",
      "2025-03-28 15:25:18,469 - __main__ - INFO - Processed 20000 users so far\n",
      "2025-03-28 15:25:18,484 - __main__ - INFO - Processed 30000 users so far\n",
      "2025-03-28 15:25:18,504 - __main__ - INFO - Processed 40000 users so far\n",
      "2025-03-28 15:25:18,519 - __main__ - INFO - Processed 50000 users so far\n",
      "2025-03-28 15:25:18,531 - __main__ - INFO - Processed 60000 users so far\n",
      "2025-03-28 15:25:18,543 - __main__ - INFO - Processed 70000 users so far\n",
      "2025-03-28 15:25:18,559 - __main__ - INFO - Processed 80000 users so far\n",
      "2025-03-28 15:25:18,571 - __main__ - INFO - Processed 90000 users so far\n",
      "2025-03-28 15:25:18,584 - __main__ - INFO - Processed 100000 users so far\n",
      "2025-03-28 15:25:18,596 - __main__ - INFO - Processed 110000 users so far\n",
      "2025-03-28 15:25:18,608 - __main__ - INFO - Processed 120000 users so far\n",
      "2025-03-28 15:25:18,620 - __main__ - INFO - Processed 130000 users so far\n",
      "2025-03-28 15:25:18,642 - __main__ - INFO - Processed 140000 users so far\n",
      "2025-03-28 15:25:18,656 - __main__ - INFO - Processed 150000 users so far\n",
      "2025-03-28 15:25:18,668 - __main__ - INFO - Processed 160000 users so far\n",
      "2025-03-28 15:25:18,680 - __main__ - INFO - Processed 170000 users so far\n",
      "2025-03-28 15:25:18,692 - __main__ - INFO - Processed 180000 users so far\n",
      "2025-03-28 15:25:18,706 - __main__ - INFO - Processed 190000 users so far\n",
      "2025-03-28 15:25:18,724 - __main__ - INFO - Processed 200000 users so far\n",
      "2025-03-28 15:25:18,749 - __main__ - INFO - Processed 210000 users so far\n",
      "2025-03-28 15:25:18,767 - __main__ - INFO - Processed 220000 users so far\n",
      "2025-03-28 15:25:18,784 - __main__ - INFO - Processed 230000 users so far\n",
      "2025-03-28 15:25:18,802 - __main__ - INFO - Processed 240000 users so far\n",
      "2025-03-28 15:25:18,823 - __main__ - INFO - Processed 250000 users so far\n",
      "2025-03-28 15:25:18,846 - __main__ - INFO - Processed 260000 users so far\n",
      "2025-03-28 15:25:18,884 - __main__ - INFO - Processed 270000 users so far\n",
      "2025-03-28 15:25:18,906 - __main__ - INFO - Processed 280000 users so far\n",
      "2025-03-28 15:25:18,928 - __main__ - INFO - Processed 290000 users so far\n",
      "2025-03-28 15:25:18,946 - __main__ - INFO - Processed 300000 users so far\n",
      "2025-03-28 15:25:18,965 - __main__ - INFO - Processed 310000 users so far\n",
      "2025-03-28 15:25:18,983 - __main__ - INFO - Processed 320000 users so far\n",
      "2025-03-28 15:25:19,001 - __main__ - INFO - Processed 330000 users so far\n",
      "2025-03-28 15:25:19,019 - __main__ - INFO - Processed 340000 users so far\n",
      "2025-03-28 15:25:19,037 - __main__ - INFO - Processed 350000 users so far\n",
      "2025-03-28 15:25:19,054 - __main__ - INFO - Processed 360000 users so far\n",
      "2025-03-28 15:25:19,072 - __main__ - INFO - Processed 370000 users so far\n",
      "2025-03-28 15:25:19,094 - __main__ - INFO - Processed 380000 users so far\n",
      "2025-03-28 15:25:19,136 - __main__ - INFO - Processed 390000 users so far\n",
      "2025-03-28 15:25:19,161 - __main__ - INFO - Processed 400000 users so far\n",
      "2025-03-28 15:25:19,184 - __main__ - INFO - Processed 410000 users so far\n",
      "2025-03-28 15:25:19,227 - __main__ - INFO - Processed 420000 users so far\n",
      "2025-03-28 15:25:19,252 - __main__ - INFO - Processed 430000 users so far\n",
      "2025-03-28 15:25:19,274 - __main__ - INFO - Processed 440000 users so far\n",
      "2025-03-28 15:25:19,316 - __main__ - INFO - Processed 450000 users so far\n",
      "2025-03-28 15:25:19,340 - __main__ - INFO - Processed 460000 users so far\n",
      "2025-03-28 15:25:19,375 - __main__ - INFO - Processed 470000 users so far\n",
      "2025-03-28 15:25:19,400 - __main__ - INFO - Processed 480000 users so far\n",
      "2025-03-28 15:25:19,422 - __main__ - INFO - Processed 490000 users so far\n",
      "2025-03-28 15:25:19,443 - __main__ - INFO - Processed 500000 users so far\n",
      "2025-03-28 15:25:19,464 - __main__ - INFO - Processed 510000 users so far\n",
      "2025-03-28 15:25:19,486 - __main__ - INFO - Processed 520000 users so far\n",
      "2025-03-28 15:25:19,506 - __main__ - INFO - Processed 530000 users so far\n",
      "2025-03-28 15:25:19,526 - __main__ - INFO - Processed 540000 users so far\n",
      "2025-03-28 15:25:19,545 - __main__ - INFO - Processed 550000 users so far\n",
      "2025-03-28 15:25:19,565 - __main__ - INFO - Processed 560000 users so far\n",
      "2025-03-28 15:25:19,585 - __main__ - INFO - Processed 570000 users so far\n",
      "2025-03-28 15:25:19,605 - __main__ - INFO - Processed 580000 users so far\n",
      "2025-03-28 15:25:19,629 - __main__ - INFO - Processed 590000 users so far\n",
      "2025-03-28 15:25:19,652 - __main__ - INFO - Processed 600000 users so far\n",
      "2025-03-28 15:25:19,671 - __main__ - INFO - Processed 610000 users so far\n",
      "2025-03-28 15:25:19,691 - __main__ - INFO - Processed 620000 users so far\n",
      "2025-03-28 15:25:19,712 - __main__ - INFO - Processed 630000 users so far\n",
      "2025-03-28 15:25:19,734 - __main__ - INFO - Processed 640000 users so far\n",
      "2025-03-28 15:25:19,753 - __main__ - INFO - Processed 650000 users so far\n",
      "2025-03-28 15:25:19,809 - __main__ - INFO - Processed 660000 users so far\n",
      "2025-03-28 15:25:19,881 - __main__ - INFO - Processed 670000 users so far\n",
      "2025-03-28 15:25:19,916 - __main__ - INFO - Processed 680000 users so far\n",
      "2025-03-28 15:25:19,942 - __main__ - INFO - Processed 690000 users so far\n",
      "2025-03-28 15:25:19,960 - __main__ - INFO - Processed 700000 users so far\n",
      "2025-03-28 15:25:19,980 - __main__ - INFO - Processed 710000 users so far\n",
      "2025-03-28 15:25:19,999 - __main__ - INFO - Processed 720000 users so far\n",
      "2025-03-28 15:25:20,022 - __main__ - INFO - Processed 730000 users so far\n",
      "2025-03-28 15:25:20,041 - __main__ - INFO - Processed 740000 users so far\n",
      "2025-03-28 15:25:20,072 - __main__ - INFO - Processed 750000 users so far\n",
      "2025-03-28 15:25:20,098 - __main__ - INFO - Processed 760000 users so far\n",
      "2025-03-28 15:25:20,121 - __main__ - INFO - Processed 770000 users so far\n",
      "2025-03-28 15:25:20,153 - __main__ - INFO - Processed 780000 users so far\n",
      "2025-03-28 15:25:20,178 - __main__ - INFO - Processed 790000 users so far\n",
      "2025-03-28 15:25:20,216 - __main__ - INFO - Processed 800000 users so far\n",
      "2025-03-28 15:25:20,242 - __main__ - INFO - Processed 810000 users so far\n",
      "2025-03-28 15:25:20,284 - __main__ - INFO - Processed 820000 users so far\n",
      "2025-03-28 15:25:20,309 - __main__ - INFO - Processed 830000 users so far\n",
      "2025-03-28 15:25:20,340 - __main__ - INFO - Processed 840000 users so far\n",
      "2025-03-28 15:25:20,373 - __main__ - INFO - Processed 850000 users so far\n",
      "2025-03-28 15:25:20,397 - __main__ - INFO - Processed 860000 users so far\n",
      "2025-03-28 15:25:22,668 - __main__ - INFO - Created DataFrame with 866901 users\n",
      "2025-03-28 15:25:22,676 - __main__ - INFO - Uploading DataFrame in 87 chunks...\n",
      "2025-03-28 15:25:23,005 - aiobotocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-03-28 15:25:28,994 - __main__ - INFO - Saved chunk 1/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--0.csv\n",
      "2025-03-28 15:25:32,030 - __main__ - INFO - Saved chunk 2/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--1.csv\n",
      "2025-03-28 15:25:33,471 - __main__ - INFO - Saved chunk 3/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--2.csv\n",
      "2025-03-28 15:25:34,575 - __main__ - INFO - Saved chunk 4/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--3.csv\n",
      "2025-03-28 15:25:35,553 - __main__ - INFO - Saved chunk 5/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--4.csv\n",
      "2025-03-28 15:25:36,560 - __main__ - INFO - Saved chunk 6/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--5.csv\n",
      "2025-03-28 15:25:37,486 - __main__ - INFO - Saved chunk 7/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--6.csv\n",
      "2025-03-28 15:25:38,382 - __main__ - INFO - Saved chunk 8/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--7.csv\n",
      "2025-03-28 15:25:39,173 - __main__ - INFO - Saved chunk 9/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--8.csv\n",
      "2025-03-28 15:25:40,006 - __main__ - INFO - Saved chunk 10/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--9.csv\n",
      "2025-03-28 15:25:40,785 - __main__ - INFO - Saved chunk 11/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--10.csv\n",
      "2025-03-28 15:25:41,531 - __main__ - INFO - Saved chunk 12/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--11.csv\n",
      "2025-03-28 15:25:42,293 - __main__ - INFO - Saved chunk 13/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--12.csv\n",
      "2025-03-28 15:25:43,060 - __main__ - INFO - Saved chunk 14/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--13.csv\n",
      "2025-03-28 15:25:43,831 - __main__ - INFO - Saved chunk 15/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--14.csv\n",
      "2025-03-28 15:25:44,654 - __main__ - INFO - Saved chunk 16/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--15.csv\n",
      "2025-03-28 15:25:45,604 - __main__ - INFO - Saved chunk 17/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--16.csv\n",
      "2025-03-28 15:25:46,566 - __main__ - INFO - Saved chunk 18/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--17.csv\n",
      "2025-03-28 15:25:47,413 - __main__ - INFO - Saved chunk 19/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--18.csv\n",
      "2025-03-28 15:25:48,547 - __main__ - INFO - Saved chunk 20/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--19.csv\n",
      "2025-03-28 15:25:49,973 - __main__ - INFO - Saved chunk 21/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--20.csv\n",
      "2025-03-28 15:25:51,022 - __main__ - INFO - Saved chunk 22/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--21.csv\n",
      "2025-03-28 15:25:52,558 - __main__ - INFO - Saved chunk 23/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--22.csv\n",
      "2025-03-28 15:25:53,681 - __main__ - INFO - Saved chunk 24/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--23.csv\n",
      "2025-03-28 15:25:55,258 - __main__ - INFO - Saved chunk 25/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--24.csv\n",
      "2025-03-28 15:25:56,924 - __main__ - INFO - Saved chunk 26/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--25.csv\n",
      "2025-03-28 15:25:58,083 - __main__ - INFO - Saved chunk 27/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--26.csv\n",
      "2025-03-28 15:25:59,693 - __main__ - INFO - Saved chunk 28/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--27.csv\n",
      "2025-03-28 15:26:00,769 - __main__ - INFO - Saved chunk 29/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--28.csv\n",
      "2025-03-28 15:26:01,820 - __main__ - INFO - Saved chunk 30/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--29.csv\n",
      "2025-03-28 15:26:03,001 - __main__ - INFO - Saved chunk 31/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--30.csv\n",
      "2025-03-28 15:26:04,160 - __main__ - INFO - Saved chunk 32/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--31.csv\n",
      "2025-03-28 15:26:05,251 - __main__ - INFO - Saved chunk 33/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--32.csv\n",
      "2025-03-28 15:26:06,394 - __main__ - INFO - Saved chunk 34/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--33.csv\n",
      "2025-03-28 15:26:07,729 - __main__ - INFO - Saved chunk 35/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--34.csv\n",
      "2025-03-28 15:26:09,241 - __main__ - INFO - Saved chunk 36/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--35.csv\n",
      "2025-03-28 15:26:10,287 - __main__ - INFO - Saved chunk 37/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--36.csv\n",
      "2025-03-28 15:26:11,339 - __main__ - INFO - Saved chunk 38/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--37.csv\n",
      "2025-03-28 15:26:12,545 - __main__ - INFO - Saved chunk 39/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--38.csv\n",
      "2025-03-28 15:26:14,047 - __main__ - INFO - Saved chunk 40/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--39.csv\n",
      "2025-03-28 15:26:15,306 - __main__ - INFO - Saved chunk 41/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--40.csv\n",
      "2025-03-28 15:26:16,543 - __main__ - INFO - Saved chunk 42/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--41.csv\n",
      "2025-03-28 15:26:18,372 - __main__ - INFO - Saved chunk 43/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--42.csv\n",
      "2025-03-28 15:26:19,647 - __main__ - INFO - Saved chunk 44/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--43.csv\n",
      "2025-03-28 15:26:20,999 - __main__ - INFO - Saved chunk 45/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--44.csv\n",
      "2025-03-28 15:26:22,253 - __main__ - INFO - Saved chunk 46/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--45.csv\n",
      "2025-03-28 15:26:23,451 - __main__ - INFO - Saved chunk 47/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--46.csv\n",
      "2025-03-28 15:26:24,865 - __main__ - INFO - Saved chunk 48/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--47.csv\n",
      "2025-03-28 15:26:26,140 - __main__ - INFO - Saved chunk 49/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--48.csv\n",
      "2025-03-28 15:26:27,744 - __main__ - INFO - Saved chunk 50/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--49.csv\n",
      "2025-03-28 15:26:33,107 - __main__ - INFO - Saved chunk 51/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--50.csv\n",
      "2025-03-28 15:26:35,681 - __main__ - INFO - Saved chunk 52/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--51.csv\n",
      "2025-03-28 15:26:37,647 - __main__ - INFO - Saved chunk 53/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--52.csv\n",
      "2025-03-28 15:26:39,328 - __main__ - INFO - Saved chunk 54/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--53.csv\n",
      "2025-03-28 15:26:40,559 - __main__ - INFO - Saved chunk 55/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--54.csv\n",
      "2025-03-28 15:26:41,597 - __main__ - INFO - Saved chunk 56/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--55.csv\n",
      "2025-03-28 15:26:42,635 - __main__ - INFO - Saved chunk 57/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--56.csv\n",
      "2025-03-28 15:26:44,078 - __main__ - INFO - Saved chunk 58/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--57.csv\n",
      "2025-03-28 15:26:45,164 - __main__ - INFO - Saved chunk 59/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--58.csv\n",
      "2025-03-28 15:26:46,274 - __main__ - INFO - Saved chunk 60/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--59.csv\n",
      "2025-03-28 15:26:47,727 - __main__ - INFO - Saved chunk 61/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--60.csv\n",
      "2025-03-28 15:26:48,710 - __main__ - INFO - Saved chunk 62/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--61.csv\n",
      "2025-03-28 15:26:49,727 - __main__ - INFO - Saved chunk 63/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--62.csv\n",
      "2025-03-28 15:26:50,712 - __main__ - INFO - Saved chunk 64/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--63.csv\n",
      "2025-03-28 15:26:51,727 - __main__ - INFO - Saved chunk 65/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--64.csv\n",
      "2025-03-28 15:26:52,692 - __main__ - INFO - Saved chunk 66/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--65.csv\n",
      "2025-03-28 15:26:53,717 - __main__ - INFO - Saved chunk 67/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--66.csv\n",
      "2025-03-28 15:26:54,713 - __main__ - INFO - Saved chunk 68/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--67.csv\n",
      "2025-03-28 15:26:55,644 - __main__ - INFO - Saved chunk 69/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--68.csv\n",
      "2025-03-28 15:26:56,694 - __main__ - INFO - Saved chunk 70/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--69.csv\n",
      "2025-03-28 15:26:58,116 - __main__ - INFO - Saved chunk 71/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--70.csv\n",
      "2025-03-28 15:26:59,159 - __main__ - INFO - Saved chunk 72/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--71.csv\n",
      "2025-03-28 15:27:00,152 - __main__ - INFO - Saved chunk 73/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--72.csv\n",
      "2025-03-28 15:27:01,076 - __main__ - INFO - Saved chunk 74/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--73.csv\n",
      "2025-03-28 15:27:02,125 - __main__ - INFO - Saved chunk 75/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--74.csv\n",
      "2025-03-28 15:27:03,156 - __main__ - INFO - Saved chunk 76/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--75.csv\n",
      "2025-03-28 15:27:04,496 - __main__ - INFO - Saved chunk 77/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--76.csv\n",
      "2025-03-28 15:27:05,497 - __main__ - INFO - Saved chunk 78/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--77.csv\n",
      "2025-03-28 15:27:06,521 - __main__ - INFO - Saved chunk 79/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--78.csv\n",
      "2025-03-28 15:27:07,492 - __main__ - INFO - Saved chunk 80/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--79.csv\n",
      "2025-03-28 15:27:08,437 - __main__ - INFO - Saved chunk 81/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--80.csv\n",
      "2025-03-28 15:27:09,408 - __main__ - INFO - Saved chunk 82/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--81.csv\n",
      "2025-03-28 15:27:10,465 - __main__ - INFO - Saved chunk 83/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--82.csv\n",
      "2025-03-28 15:27:11,518 - __main__ - INFO - Saved chunk 84/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--83.csv\n",
      "2025-03-28 15:27:12,903 - __main__ - INFO - Saved chunk 85/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--84.csv\n",
      "2025-03-28 15:27:13,883 - __main__ - INFO - Saved chunk 86/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--85.csv\n",
      "2025-03-28 15:27:14,702 - __main__ - INFO - Saved chunk 87/87 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_accounts_1743200676--86.csv\n",
      "2025-03-28 15:27:14,709 - __main__ - INFO - Processing account batch 1/87\n",
      "2025-03-28 15:27:16,724 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:16,725 - __main__ - INFO - Processing account batch 2/87\n",
      "2025-03-28 15:27:17,475 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:17,476 - __main__ - INFO - Processing account batch 3/87\n",
      "2025-03-28 15:27:18,430 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:18,432 - __main__ - INFO - Processing account batch 4/87\n",
      "2025-03-28 15:27:19,126 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:19,127 - __main__ - INFO - Processing account batch 5/87\n",
      "2025-03-28 15:27:19,790 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:19,792 - __main__ - INFO - Processing account batch 6/87\n",
      "2025-03-28 15:27:20,439 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:20,442 - __main__ - INFO - Processing account batch 7/87\n",
      "2025-03-28 15:27:21,046 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:21,049 - __main__ - INFO - Processing account batch 8/87\n",
      "2025-03-28 15:27:21,670 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:21,671 - __main__ - INFO - Processing account batch 9/87\n",
      "2025-03-28 15:27:22,312 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:22,313 - __main__ - INFO - Processing account batch 10/87\n",
      "2025-03-28 15:27:22,898 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:22,898 - __main__ - INFO - Processing account batch 11/87\n",
      "2025-03-28 15:27:23,553 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:23,554 - __main__ - INFO - Processing account batch 12/87\n",
      "2025-03-28 15:27:24,148 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:24,150 - __main__ - INFO - Processing account batch 13/87\n",
      "2025-03-28 15:27:24,792 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:24,797 - __main__ - INFO - Processing account batch 14/87\n",
      "2025-03-28 15:27:25,408 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:25,410 - __main__ - INFO - Processing account batch 15/87\n",
      "2025-03-28 15:27:26,096 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:26,100 - __main__ - INFO - Processing account batch 16/87\n",
      "2025-03-28 15:27:26,702 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:26,703 - __main__ - INFO - Processing account batch 17/87\n",
      "2025-03-28 15:27:27,293 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:27,294 - __main__ - INFO - Processing account batch 18/87\n",
      "2025-03-28 15:27:27,873 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:27,876 - __main__ - INFO - Processing account batch 19/87\n",
      "2025-03-28 15:27:28,458 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:28,459 - __main__ - INFO - Processing account batch 20/87\n",
      "2025-03-28 15:27:29,079 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:29,082 - __main__ - INFO - Processing account batch 21/87\n",
      "2025-03-28 15:27:29,680 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:29,680 - __main__ - INFO - Processing account batch 22/87\n",
      "2025-03-28 15:27:30,321 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:30,322 - __main__ - INFO - Processing account batch 23/87\n",
      "2025-03-28 15:27:30,944 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:30,947 - __main__ - INFO - Processing account batch 24/87\n",
      "2025-03-28 15:27:31,580 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:31,583 - __main__ - INFO - Processing account batch 25/87\n",
      "2025-03-28 15:27:32,217 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:32,219 - __main__ - INFO - Processing account batch 26/87\n",
      "2025-03-28 15:27:32,828 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:32,829 - __main__ - INFO - Processing account batch 27/87\n",
      "2025-03-28 15:27:33,445 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:33,446 - __main__ - INFO - Processing account batch 28/87\n",
      "2025-03-28 15:27:34,054 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:34,055 - __main__ - INFO - Processing account batch 29/87\n",
      "2025-03-28 15:27:34,716 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:34,718 - __main__ - INFO - Processing account batch 30/87\n",
      "2025-03-28 15:27:35,312 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:35,313 - __main__ - INFO - Processing account batch 31/87\n",
      "2025-03-28 15:27:35,929 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:35,930 - __main__ - INFO - Processing account batch 32/87\n",
      "2025-03-28 15:27:36,881 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:36,883 - __main__ - INFO - Processing account batch 33/87\n",
      "2025-03-28 15:27:37,510 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:37,511 - __main__ - INFO - Processing account batch 34/87\n",
      "2025-03-28 15:27:38,119 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:38,123 - __main__ - INFO - Processing account batch 35/87\n",
      "2025-03-28 15:27:38,753 - __main__ - INFO - Created/updated 10001 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:38,754 - __main__ - INFO - Processing account batch 36/87\n",
      "2025-03-28 15:27:39,338 - __main__ - INFO - Created/updated 10005 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:39,340 - __main__ - INFO - Processing account batch 37/87\n",
      "2025-03-28 15:27:39,921 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:39,923 - __main__ - INFO - Processing account batch 38/87\n",
      "2025-03-28 15:27:40,566 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:40,567 - __main__ - INFO - Processing account batch 39/87\n",
      "2025-03-28 15:27:41,240 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:41,243 - __main__ - INFO - Processing account batch 40/87\n",
      "2025-03-28 15:27:41,835 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:41,836 - __main__ - INFO - Processing account batch 41/87\n",
      "2025-03-28 15:27:42,485 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:42,487 - __main__ - INFO - Processing account batch 42/87\n",
      "2025-03-28 15:27:43,154 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:43,157 - __main__ - INFO - Processing account batch 43/87\n",
      "2025-03-28 15:27:43,772 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:43,774 - __main__ - INFO - Processing account batch 44/87\n",
      "2025-03-28 15:27:44,410 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:44,412 - __main__ - INFO - Processing account batch 45/87\n",
      "2025-03-28 15:27:45,028 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:45,029 - __main__ - INFO - Processing account batch 46/87\n",
      "2025-03-28 15:27:45,629 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:45,630 - __main__ - INFO - Processing account batch 47/87\n",
      "2025-03-28 15:27:46,254 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:46,256 - __main__ - INFO - Processing account batch 48/87\n",
      "2025-03-28 15:27:46,998 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:46,999 - __main__ - INFO - Processing account batch 49/87\n",
      "2025-03-28 15:27:47,956 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:47,958 - __main__ - INFO - Processing account batch 50/87\n",
      "2025-03-28 15:27:48,569 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:48,573 - __main__ - INFO - Processing account batch 51/87\n",
      "2025-03-28 15:27:49,237 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:49,238 - __main__ - INFO - Processing account batch 52/87\n",
      "2025-03-28 15:27:49,835 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:49,839 - __main__ - INFO - Processing account batch 53/87\n",
      "2025-03-28 15:27:50,424 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:50,426 - __main__ - INFO - Processing account batch 54/87\n",
      "2025-03-28 15:27:51,051 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:51,052 - __main__ - INFO - Processing account batch 55/87\n",
      "2025-03-28 15:27:51,683 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:51,686 - __main__ - INFO - Processing account batch 56/87\n",
      "2025-03-28 15:27:52,245 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:52,248 - __main__ - INFO - Processing account batch 57/87\n",
      "2025-03-28 15:27:52,824 - __main__ - INFO - Created/updated 10005 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:52,827 - __main__ - INFO - Processing account batch 58/87\n",
      "2025-03-28 15:27:53,398 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:53,399 - __main__ - INFO - Processing account batch 59/87\n",
      "2025-03-28 15:27:53,965 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:53,967 - __main__ - INFO - Processing account batch 60/87\n",
      "2025-03-28 15:27:54,552 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:54,554 - __main__ - INFO - Processing account batch 61/87\n",
      "2025-03-28 15:27:55,165 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:55,166 - __main__ - INFO - Processing account batch 62/87\n",
      "2025-03-28 15:27:55,763 - __main__ - INFO - Created/updated 10001 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:55,764 - __main__ - INFO - Processing account batch 63/87\n",
      "2025-03-28 15:27:56,334 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:56,335 - __main__ - INFO - Processing account batch 64/87\n",
      "2025-03-28 15:27:56,965 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:56,966 - __main__ - INFO - Processing account batch 65/87\n",
      "2025-03-28 15:27:57,609 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:57,610 - __main__ - INFO - Processing account batch 66/87\n",
      "2025-03-28 15:27:58,571 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:58,572 - __main__ - INFO - Processing account batch 67/87\n",
      "2025-03-28 15:27:59,205 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:59,207 - __main__ - INFO - Processing account batch 68/87\n",
      "2025-03-28 15:27:59,802 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:27:59,804 - __main__ - INFO - Processing account batch 69/87\n",
      "2025-03-28 15:28:00,391 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:00,393 - __main__ - INFO - Processing account batch 70/87\n",
      "2025-03-28 15:28:00,987 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:00,988 - __main__ - INFO - Processing account batch 71/87\n",
      "2025-03-28 15:28:01,594 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:01,599 - __main__ - INFO - Processing account batch 72/87\n",
      "2025-03-28 15:28:02,212 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:02,214 - __main__ - INFO - Processing account batch 73/87\n",
      "2025-03-28 15:28:02,781 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:02,784 - __main__ - INFO - Processing account batch 74/87\n",
      "2025-03-28 15:28:03,373 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:03,374 - __main__ - INFO - Processing account batch 75/87\n",
      "2025-03-28 15:28:03,974 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:03,975 - __main__ - INFO - Processing account batch 76/87\n",
      "2025-03-28 15:28:04,551 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:04,553 - __main__ - INFO - Processing account batch 77/87\n",
      "2025-03-28 15:28:05,227 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:05,229 - __main__ - INFO - Processing account batch 78/87\n",
      "2025-03-28 15:28:05,799 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:05,800 - __main__ - INFO - Processing account batch 79/87\n",
      "2025-03-28 15:28:06,456 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:06,458 - __main__ - INFO - Processing account batch 80/87\n",
      "2025-03-28 15:28:07,046 - __main__ - INFO - Created/updated 10001 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:07,047 - __main__ - INFO - Processing account batch 81/87\n",
      "2025-03-28 15:28:07,683 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:07,684 - __main__ - INFO - Processing account batch 82/87\n",
      "2025-03-28 15:28:08,292 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:08,296 - __main__ - INFO - Processing account batch 83/87\n",
      "2025-03-28 15:28:09,198 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:09,200 - __main__ - INFO - Processing account batch 84/87\n",
      "2025-03-28 15:28:09,764 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:09,764 - __main__ - INFO - Processing account batch 85/87\n",
      "2025-03-28 15:28:10,336 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:10,338 - __main__ - INFO - Processing account batch 86/87\n",
      "2025-03-28 15:28:10,887 - __main__ - INFO - Created/updated 10000 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:10,887 - __main__ - INFO - Processing account batch 87/87\n",
      "2025-03-28 15:28:11,373 - __main__ - INFO - Created/updated 6901 Farcaster accounts in Neo4j\n",
      "2025-03-28 15:28:12,259 - __main__ - INFO - Uploading DataFrame in 40 chunks...\n",
      "2025-03-28 15:28:17,535 - __main__ - INFO - Saved chunk 1/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--0.csv\n",
      "2025-03-28 15:28:20,541 - __main__ - INFO - Saved chunk 2/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--1.csv\n",
      "2025-03-28 15:28:22,622 - __main__ - INFO - Saved chunk 3/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--2.csv\n",
      "2025-03-28 15:28:24,448 - __main__ - INFO - Saved chunk 4/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--3.csv\n",
      "2025-03-28 15:28:25,970 - __main__ - INFO - Saved chunk 5/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--4.csv\n",
      "2025-03-28 15:28:27,367 - __main__ - INFO - Saved chunk 6/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--5.csv\n",
      "2025-03-28 15:28:28,547 - __main__ - INFO - Saved chunk 7/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--6.csv\n",
      "2025-03-28 15:28:29,720 - __main__ - INFO - Saved chunk 8/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--7.csv\n",
      "2025-03-28 15:28:31,290 - __main__ - INFO - Saved chunk 9/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--8.csv\n",
      "2025-03-28 15:28:32,391 - __main__ - INFO - Saved chunk 10/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--9.csv\n",
      "2025-03-28 15:28:33,495 - __main__ - INFO - Saved chunk 11/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--10.csv\n",
      "2025-03-28 15:28:35,230 - __main__ - INFO - Saved chunk 12/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--11.csv\n",
      "2025-03-28 15:28:36,365 - __main__ - INFO - Saved chunk 13/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--12.csv\n",
      "2025-03-28 15:28:37,454 - __main__ - INFO - Saved chunk 14/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--13.csv\n",
      "2025-03-28 15:28:38,519 - __main__ - INFO - Saved chunk 15/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--14.csv\n",
      "2025-03-28 15:28:39,612 - __main__ - INFO - Saved chunk 16/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--15.csv\n",
      "2025-03-28 15:28:40,681 - __main__ - INFO - Saved chunk 17/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--16.csv\n",
      "2025-03-28 15:28:41,751 - __main__ - INFO - Saved chunk 18/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--17.csv\n",
      "2025-03-28 15:28:42,809 - __main__ - INFO - Saved chunk 19/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--18.csv\n",
      "2025-03-28 15:28:43,879 - __main__ - INFO - Saved chunk 20/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--19.csv\n",
      "2025-03-28 15:28:44,947 - __main__ - INFO - Saved chunk 21/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--20.csv\n",
      "2025-03-28 15:28:46,379 - __main__ - INFO - Saved chunk 22/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--21.csv\n",
      "2025-03-28 15:28:47,495 - __main__ - INFO - Saved chunk 23/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--22.csv\n",
      "2025-03-28 15:28:49,030 - __main__ - INFO - Saved chunk 24/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--23.csv\n",
      "2025-03-28 15:28:50,158 - __main__ - INFO - Saved chunk 25/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--24.csv\n",
      "2025-03-28 15:28:51,266 - __main__ - INFO - Saved chunk 26/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--25.csv\n",
      "2025-03-28 15:28:52,469 - __main__ - INFO - Saved chunk 27/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--26.csv\n",
      "2025-03-28 15:28:53,570 - __main__ - INFO - Saved chunk 28/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--27.csv\n",
      "2025-03-28 15:28:54,658 - __main__ - INFO - Saved chunk 29/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--28.csv\n",
      "2025-03-28 15:28:55,679 - __main__ - INFO - Saved chunk 30/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--29.csv\n",
      "2025-03-28 15:28:56,779 - __main__ - INFO - Saved chunk 31/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--30.csv\n",
      "2025-03-28 15:28:57,994 - __main__ - INFO - Saved chunk 32/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--31.csv\n",
      "2025-03-28 15:28:59,621 - __main__ - INFO - Saved chunk 33/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--32.csv\n",
      "2025-03-28 15:29:00,784 - __main__ - INFO - Saved chunk 34/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--33.csv\n",
      "2025-03-28 15:29:02,325 - __main__ - INFO - Saved chunk 35/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--34.csv\n",
      "2025-03-28 15:29:03,422 - __main__ - INFO - Saved chunk 36/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--35.csv\n",
      "2025-03-28 15:29:04,496 - __main__ - INFO - Saved chunk 37/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--36.csv\n",
      "2025-03-28 15:29:05,539 - __main__ - INFO - Saved chunk 38/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--37.csv\n",
      "2025-03-28 15:29:06,654 - __main__ - INFO - Saved chunk 39/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--38.csv\n",
      "2025-03-28 15:29:07,204 - __main__ - INFO - Saved chunk 40/40 to https://s3-us-east-2.amazonaws.com/census-warpcast-account-metadata/warpcast_verif_1743200676--39.csv\n",
      "2025-03-28 15:29:07,209 - __main__ - INFO - Processing verification batch 1/40\n"
     ]
    },
    {
     "ename": "CypherSyntaxError",
     "evalue": "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'WHERE': expected 'FOREACH', 'ORDER BY', 'CALL', 'CREATE', 'LOAD CSV', 'DELETE', 'DETACH', 'FIELDTERMINATOR', 'FINISH', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REMOVE', 'RETURN', 'SET', 'SKIP', 'UNION', 'UNWIND', 'USE', 'WITH' or <EOF> (line 3, column 13 (offset: 162))\n\"            WHERE row.verification_address IS NOT NULL AND trim(row.verification_address) <> ''\"\n             ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGqlError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;31mGqlError\u001b[0m: {gql_status: 42I06} {gql_status_description: error: syntax error or access rule violation - invalid input. Invalid input 'WHERE', expected: 'FOREACH', 'ORDER BY', 'CALL', 'CREATE', 'LOAD CSV', 'DELETE', 'DETACH', 'FIELDTERMINATOR', 'FINISH', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REMOVE', 'RETURN', 'SET', 'SKIP', 'UNION', 'UNWIND', 'USE', 'WITH' or <EOF>.} {message: 42I06: Invalid input 'WHERE', expected: 'FOREACH', 'ORDER BY', 'CALL', 'CREATE', 'LOAD CSV', 'DELETE', 'DETACH', 'FIELDTERMINATOR', 'FINISH', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REMOVE', 'RETURN', 'SET', 'SKIP', 'UNION', 'UNWIND', 'USE', 'WITH' or <EOF>.} {diagnostic_record: {'_classification': 'CLIENT_ERROR', '_position': {'column': 13, 'offset': 162, 'line': 3}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}} {raw_classification: CLIENT_ERROR}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 215\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Run the main function if this script is executed directly\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 175\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing verification batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(verif_urls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124mLOAD CSV WITH HEADERS FROM \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS row\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124mWHERE row.verification_address IS NOT NULL AND trim(row.verification_address) <> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124mRETURN count(*)\u001b[39m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 175\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_cypher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m count \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    177\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m verification links\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 81\u001b[0m, in \u001b[0;36mexecute_cypher\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute a Cypher query in Neo4j\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m neo4j_driver\u001b[38;5;241m.\u001b[39msession(database\u001b[38;5;241m=\u001b[39mNEO4J_DATABASE) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 81\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(result)\n",
      "File \u001b[0;32m~/dev/census/census-data/env/lib/python3.10/site-packages/neo4j/_sync/work/session.py:328\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m bookmarks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bookmarks()\n\u001b[1;32m    327\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_min_severity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_disabled_classifications\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\n",
      "File \u001b[0;32m~/dev/census/census-data/env/lib/python3.10/site-packages/neo4j/_sync/work/result.py:236\u001b[0m, in \u001b[0;36mResult._run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pull()\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/census/census-data/env/lib/python3.10/site-packages/neo4j/_sync/work/result.py:430\u001b[0m, in \u001b[0;36mResult._attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/census/census-data/env/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:184\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[0;32m~/dev/census/census-data/env/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:864\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[1;32m    861\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    862\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[1;32m    863\u001b[0m )\n\u001b[0;32m--> 864\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/dev/census/census-data/env/lib/python3.10/site-packages/neo4j/_sync/io/_bolt5.py:1208\u001b[0m, in \u001b[0;36mBolt5x7._process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enrich_error_diagnostic_record(summary_metadata)\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1208\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[0;32m~/dev/census/census-data/env/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:254\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    252\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    253\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hydrate_error(metadata)\n",
      "\u001b[0;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'WHERE': expected 'FOREACH', 'ORDER BY', 'CALL', 'CREATE', 'LOAD CSV', 'DELETE', 'DETACH', 'FIELDTERMINATOR', 'FINISH', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REMOVE', 'RETURN', 'SET', 'SKIP', 'UNION', 'UNWIND', 'USE', 'WITH' or <EOF> (line 3, column 13 (offset: 162))\n\"            WHERE row.verification_address IS NOT NULL AND trim(row.verification_address) <> ''\"\n             ^}"
     ]
    }
   ],
   "source": [
    "# Main execution script - no classes\n",
    "def main():\n",
    "    timestamp = int(datetime.now().timestamp())\n",
    "    test_mode = False  # Set to True for testing with a small subset\n",
    "    test_limit = 100   # Only used if test_mode is True\n",
    "    \n",
    "    # Step 1: Load data from S3\n",
    "    logger.info(\"Loading Warpcast account data from S3\")\n",
    "    latest_file = get_latest_file('warpcast/users/')\n",
    "    if not latest_file:\n",
    "        logger.error(\"No files found in the S3 bucket\")\n",
    "        return False\n",
    "        \n",
    "    content = get_file_content(latest_file)\n",
    "    if not content:\n",
    "        logger.error(\"Failed to read file content\")\n",
    "        return False\n",
    "    \n",
    "    # Step 2: Parse JSON\n",
    "    try:\n",
    "        raw_data = json.loads(content)\n",
    "        logger.info(f\"Successfully loaded data with {len(raw_data)} batch responses\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Error parsing JSON: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Extract and flatten user data\n",
    "    logger.info(\"Processing Warpcast account data\")\n",
    "    all_users = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    for batch in raw_data:\n",
    "        if not batch.get('success', False):\n",
    "            continue\n",
    "            \n",
    "        batch_data = batch.get('data', {})\n",
    "        users = batch_data.get('users', [])\n",
    "        \n",
    "        for user in users:\n",
    "            if user:  # Skip empty entries\n",
    "                # Flatten user object\n",
    "                flat_user = {\n",
    "                    'fid': user.get('fid'),\n",
    "                    'username': user.get('username'),\n",
    "                    'display_name': user.get('displayName'),\n",
    "                    'custody_address': user.get('custodyAddress'),\n",
    "                    'pfp_url': user.get('pfp_url'),\n",
    "                    'bio': user.get('profile', {}).get('bio', {}).get('text'),\n",
    "                    'followingCount': user.get(('following_count')),\n",
    "                    'followerCount': int(user.get('follower_count')),\n",
    "                    'verified': user.get('verified', False),\n",
    "                    'power_badge': user.get('powerBadge', False)\n",
    "                }\n",
    "                \n",
    "                # Extract mentioned profiles from bio\n",
    "                if flat_user['bio'] and isinstance(flat_user['bio'], str):\n",
    "                    mentions = re.findall(r'@(\\w+)', flat_user['bio'])\n",
    "                    if mentions:\n",
    "                        flat_user['mentioned_profiles'] = json.dumps(mentions)\n",
    "                \n",
    "                # Add location data if available\n",
    "                if 'profile' in user and 'location' in user['profile'] and user['profile']['location']:\n",
    "                    location = user['profile']['location']\n",
    "                    \n",
    "                    if 'address' in location and location['address']:\n",
    "                        address = location['address']\n",
    "                        flat_user['city'] = address.get('city')\n",
    "                        flat_user['state'] = address.get('state')\n",
    "                        flat_user['state_code'] = address.get('stateCode')\n",
    "                        flat_user['country'] = address.get('country')\n",
    "                        flat_user['country_code'] = address.get('countryCode')\n",
    "                \n",
    "                # Handle verifications - they're strings, not objects\n",
    "                if 'verifications' in user and user['verifications'] and len(user['verifications']) > 0:\n",
    "                    flat_user['verification_address'] = user['verifications'][0]\n",
    "                    flat_user['verification_type'] = 'ethereum'\n",
    "                \n",
    "                # Clean null values\n",
    "                for key, value in flat_user.items():\n",
    "                    if value is None:\n",
    "                        flat_user[key] = \"\"\n",
    "                \n",
    "                all_users.append(flat_user)\n",
    "                processed_count += 1\n",
    "                \n",
    "                if processed_count % 10000 == 0:\n",
    "                    logger.info(f\"Processed {processed_count} users so far\")\n",
    "    \n",
    "    # If test mode, limit the number of records\n",
    "    if test_mode:\n",
    "        logger.info(f\"Test mode: limiting to {test_limit} records\")\n",
    "        all_users = all_users[:test_limit]\n",
    "    \n",
    "    # Step 4: Convert to DataFrame\n",
    "    df = pd.DataFrame(all_users)\n",
    "    logger.info(f\"Created DataFrame with {len(df)} users\")\n",
    "    \n",
    "    # Step 5: Save to S3 and process with Neo4j\n",
    "    # 5.1 Create accounts\n",
    "    accounts_urls = save_df_as_csv(df, f\"warpcast_accounts_{timestamp}\")\n",
    "    \n",
    "    for i, url in enumerate(accounts_urls):\n",
    "        logger.info(f\"Processing account batch {i+1}/{len(accounts_urls)}\")\n",
    "        count = create_farcaster_accounts(url)\n",
    "    \n",
    "    \n",
    "    logger.info(\"Completed Warpcast account ingestion process\")\n",
    "    return True\n",
    "\n",
    "# Run the main function if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:36:18,642 - __main__ - INFO - Starting to fetch first 100 Warpcast accounts\n",
      "2025-03-28 15:36:18,643 - __main__ - INFO - Querying Neynar API for FIDs: [1, 2, 3, 4, 5]... (total: 100)\n",
      "2025-03-28 15:36:19,170 - __main__ - INFO - Rate limit remaining: 299\n",
      "2025-03-28 15:36:19,173 - __main__ - INFO - Processing 100 users\n",
      "2025-03-28 15:37:32,170 - __main__ - INFO - Successfully created/updated 100 Warpcast account nodes\n",
      "2025-03-28 15:37:32,172 - __main__ - INFO - Completed Warpcast account fetch and node creation\n"
     ]
    }
   ],
   "source": [
    "# %% cell 4 code - Fetch first 100 accounts from Neynar API and create nodes\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Neynar API configuration\n",
    "NEYNAR_API_KEY = os.getenv('NEYNAR_API_KEY')\n",
    "REQUESTS_PER_MINUTE = 30\n",
    "REQUEST_DELAY = (60.0 / REQUESTS_PER_MINUTE) + 0.2\n",
    "\n",
    "# Neo4j connection function from above\n",
    "def execute_cypher(query, params=None):\n",
    "    from neo4j import GraphDatabase\n",
    "    \n",
    "    uri = os.getenv('NEO4J_URI')\n",
    "    username = os.getenv('NEO4J_USERNAME')\n",
    "    password = os.getenv('NEO4J_PASSWORD')\n",
    "    \n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, params)\n",
    "        records = list(result)\n",
    "        driver.close()\n",
    "        return records\n",
    "\n",
    "def query_neynar_api_for_users(fids):\n",
    "    \"\"\"Query Neynar API for user data by FIDs\"\"\"\n",
    "    base_url = \"https://api.neynar.com/v2/farcaster/user/bulk\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"api_key\": NEYNAR_API_KEY\n",
    "    }\n",
    "    params = {\n",
    "        \"fids\": \",\".join(map(str, fids))\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Querying Neynar API for FIDs: {fids[:5]}... (total: {len(fids)})\")\n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        \n",
    "        if 'X-RateLimit-Remaining' in response.headers:\n",
    "            logger.info(f\"Rate limit remaining: {response.headers['X-RateLimit-Remaining']}\")\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error querying Neynar API: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def process_user_data(user_data):\n",
    "    \"\"\"Process user data and create nodes in Neo4j\"\"\"\n",
    "    if not user_data or 'users' not in user_data:\n",
    "        logger.error(\"No valid user data found\")\n",
    "        return 0\n",
    "    \n",
    "    users = user_data['users']\n",
    "    logger.info(f\"Processing {len(users)} users\")\n",
    "    \n",
    "    # Convert to DataFrame for easier processing\n",
    "    users_df = pd.json_normalize(users)\n",
    "    \n",
    "    # Create nodes one by one\n",
    "    created_count = 0\n",
    "    for _, row in users_df.iterrows():\n",
    "        try:\n",
    "            # Extract user data\n",
    "            username = row.get('username', '')\n",
    "            display_name = row.get('displayName', '')\n",
    "            bio = row.get('profile.bio.text', '')\n",
    "            \n",
    "            # Create aggregated text field\n",
    "            agg_text = f\"{username} {display_name} {bio}\".strip()\n",
    "            \n",
    "            user_data = {\n",
    "                'fid': str(row.get('fid', '')),\n",
    "                'username': username,\n",
    "                'display_name': display_name,\n",
    "                'pfp_url': row.get('pfp.url', ''),\n",
    "                'follower_count': str(row.get('followerCount', 0)),\n",
    "                'following_count': str(row.get('followingCount', 0)),\n",
    "                'bio': bio,\n",
    "                'agg_text': agg_text\n",
    "            }\n",
    "            \n",
    "            # Create Cypher query for this user\n",
    "            query = \"\"\"\n",
    "            MERGE (a:Account:Warpcast {fid: $fid})\n",
    "            ON CREATE SET\n",
    "                a.username = $username,\n",
    "                a.displayName = $display_name,\n",
    "                a.pfpUrl = $pfp_url,\n",
    "                a.followerCount = $follower_count,\n",
    "                a.followingCount = $following_count,\n",
    "                a.bio = $bio,\n",
    "                a.aggText = $agg_text,\n",
    "                a.createdDt = datetime(),\n",
    "                a.lastUpdatedDt = datetime()\n",
    "            ON MATCH SET\n",
    "                a.username = $username,\n",
    "                a.displayName = $display_name,\n",
    "                a.pfpUrl = $pfp_url,\n",
    "                a.followerCount = $follower_count,\n",
    "                a.followingCount = $following_count,\n",
    "                a.bio = $bio,\n",
    "                a.aggText = $agg_text,\n",
    "                a.lastUpdatedDt = datetime()\n",
    "            RETURN a\n",
    "            \"\"\"\n",
    "            \n",
    "            # Execute query\n",
    "            result = execute_cypher(query, user_data)\n",
    "            created_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing user {row.get('fid')}: {str(e)}\")\n",
    "    \n",
    "    return created_count\n",
    "\n",
    "# Main function to fetch and process first 100 accounts\n",
    "def fetch_first_100_accounts():\n",
    "    logger.info(\"Starting to fetch first 100 Warpcast accounts\")\n",
    "    \n",
    "    # Define FID range (1-100)\n",
    "    start_fid = 1\n",
    "    end_fid = 100\n",
    "    batch_size = 100\n",
    "    \n",
    "    # Create batch of FIDs\n",
    "    fids = list(range(start_fid, end_fid + 1))\n",
    "    \n",
    "    # Query API\n",
    "    user_data = query_neynar_api_for_users(fids)\n",
    "    \n",
    "    # Process and create nodes\n",
    "    if user_data and not user_data.get('error'):\n",
    "        created_count = process_user_data(user_data)\n",
    "        logger.info(f\"Successfully created/updated {created_count} Warpcast account nodes\")\n",
    "    else:\n",
    "        logger.error(f\"Failed to fetch user data: {user_data.get('error')}\")\n",
    "    \n",
    "    logger.info(\"Completed Warpcast account fetch and node creation\")\n",
    "\n",
    "# Run the function\n",
    "fetch_first_100_accounts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the latest file from S3 with a given prefix\n",
    "def get_latest_file(prefix):\n",
    "    \"\"\"\n",
    "    Get the latest file from S3 bucket with the given prefix\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = s3_client.list_objects_v2(\n",
    "            Bucket=BUCKET_NAME,\n",
    "            Prefix=prefix\n",
    "        )\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            logger.error(f\"No files found with prefix {prefix}\")\n",
    "            return None\n",
    "            \n",
    "        all_files = sorted(response['Contents'], key=lambda x: x['LastModified'], reverse=True)\n",
    "        \n",
    "        if not all_files:\n",
    "            logger.error(f\"No files found with prefix {prefix}\")\n",
    "            return None\n",
    "            \n",
    "        latest_file = all_files[0]['Key']\n",
    "        logger.info(f\"Found latest file: {latest_file}\")\n",
    "        \n",
    "        return latest_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error accessing S3: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Function to get content of a file from S3\n",
    "def get_file_content(key):\n",
    "    \"\"\"\n",
    "    Get content of a file from S3\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=BUCKET_NAME, Key=key)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        \n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting S3 file content: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Function to save a DataFrame to S3 as CSV\n",
    "def save_csv_to_s3(df, prefix):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to S3 as CSV\n",
    "    Returns the S3 URL of the saved file\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        logger.warning(\"Attempted to save empty DataFrame\")\n",
    "        return None\n",
    "        \n",
    "    logger.info(f\"Saving DataFrame with {len(df)} rows to S3 with prefix {prefix}\")\n",
    "    \n",
    "    # Convert to CSV\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    csv_data = csv_buffer.getvalue()\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = int(datetime.now().timestamp())\n",
    "    chunk_name = f\"{prefix}_{timestamp}.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Upload to S3 with public-read ACL\n",
    "        s3_client.put_object(\n",
    "            Bucket=BUCKET_NAME,\n",
    "            Key=chunk_name,\n",
    "            Body=csv_data,\n",
    "            ContentType='text/csv',\n",
    "            ACL='public-read'  # Make it publicly accessible\n",
    "        )\n",
    "        \n",
    "        # Get the S3 URL\n",
    "        s3_url = f\"https://{BUCKET_NAME}.s3.amazonaws.com/{chunk_name}\"\n",
    "        logger.info(f\"Successfully saved to {s3_url}\")\n",
    "        \n",
    "        return s3_url\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving to S3: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to flatten the nested user object\n",
    "def flatten_user(user):\n",
    "    \"\"\"\n",
    "    Flatten the nested user object into a flat dictionary\n",
    "    \"\"\"\n",
    "    flat_user = {\n",
    "        'fid': user.get('fid'),\n",
    "        'username': user.get('username'),\n",
    "        'display_name': user.get('displayName'),\n",
    "        'custody_address': user.get('custodyAddress'),\n",
    "        'pfp_url': user.get('pfp', {}).get('url'),\n",
    "        'bio': user.get('profile', {}).get('bio', {}).get('text'),\n",
    "        'following_count': user.get('followingCount'),\n",
    "        'follower_count': user.get('followerCount'),\n",
    "        'verified': user.get('verified', False),\n",
    "        'power_badge': user.get('powerBadge', False)\n",
    "    }\n",
    "    \n",
    "    # Extract mentioned profiles from bio if available\n",
    "    if flat_user['bio'] and isinstance(flat_user['bio'], str):\n",
    "        # Find all @username mentions in the bio\n",
    "        mentions = re.findall(r'@(\\w+)', flat_user['bio'])\n",
    "        if mentions:\n",
    "            flat_user['mentioned_profiles'] = json.dumps(mentions)\n",
    "        else:\n",
    "            flat_user['mentioned_profiles'] = ''\n",
    "    else:\n",
    "        flat_user['mentioned_profiles'] = ''\n",
    "    \n",
    "    # Add additional fields from profile if available\n",
    "    if 'profile' in user:\n",
    "        profile = user['profile']\n",
    "        \n",
    "        # Add location data if available\n",
    "        if 'location' in profile and profile['location']:\n",
    "            location = profile['location']\n",
    "            \n",
    "            if 'address' in location and location['address']:\n",
    "                address = location['address']\n",
    "                flat_user['city'] = address.get('city', '')\n",
    "                flat_user['state'] = address.get('state', '')\n",
    "                flat_user['state_code'] = address.get('stateCode', '')\n",
    "                flat_user['country'] = address.get('country', '')\n",
    "                flat_user['country_code'] = address.get('countryCode', '')\n",
    "            else:\n",
    "                flat_user['city'] = ''\n",
    "                flat_user['state'] = ''\n",
    "                flat_user['state_code'] = ''\n",
    "                flat_user['country'] = ''\n",
    "                flat_user['country_code'] = ''\n",
    "        else:\n",
    "            flat_user['city'] = ''\n",
    "            flat_user['state'] = ''\n",
    "            flat_user['state_code'] = ''\n",
    "            flat_user['country'] = ''\n",
    "            flat_user['country_code'] = ''\n",
    "    \n",
    "    # Handle verifications\n",
    "    if 'verifications' in user and user['verifications'] and len(user['verifications']) > 0:\n",
    "        # Just take the first verification address as a string\n",
    "        flat_user['verification_address'] = user['verifications'][0]\n",
    "        flat_user['verification_type'] = 'ethereum'  # Default to ethereum\n",
    "    else:\n",
    "        flat_user['verification_address'] = ''\n",
    "        flat_user['verification_type'] = ''\n",
    "    \n",
    "    # Clean any null values\n",
    "    for key, value in flat_user.items():\n",
    "        if value is None:\n",
    "            flat_user[key] = \"\"\n",
    "            \n",
    "    return flat_user\n",
    "\n",
    "\n",
    "# Function to process raw Warpcast data\n",
    "def process_warpcast_data(raw_data):\n",
    "    \"\"\"\n",
    "    Process raw Warpcast data into a DataFrame\n",
    "    \"\"\"\n",
    "    logger.info(\"Processing Warpcast account data\")\n",
    "    \n",
    "    # Create a list to collect all user data\n",
    "    all_users = []\n",
    "    \n",
    "    # Iterate through each batch in the response\n",
    "    for batch_idx, batch in enumerate(raw_data):\n",
    "        if not batch.get('success', False):\n",
    "            logger.warning(f\"Skipping unsuccessful batch {batch_idx}\")\n",
    "            continue\n",
    "            \n",
    "        # Extract users data from the batch\n",
    "        batch_data = batch.get('data', {})\n",
    "        users = batch_data.get('users', [])\n",
    "        \n",
    "        # Add each user to our collection\n",
    "        for user in users:\n",
    "            if user:  # Skip empty entries\n",
    "                # Flatten the user object for easier CSV handling\n",
    "                flat_user = flatten_user(user)\n",
    "                all_users.append(flat_user)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    users_df = pd.DataFrame(all_users)\n",
    "    \n",
    "    # Apply sanitization to text fields\n",
    "    text_columns = ['username', 'display_name', 'bio']\n",
    "    for col in text_columns:\n",
    "        if col in users_df.columns:\n",
    "            users_df[col] = users_df[col].apply(sanitize_text)\n",
    "    \n",
    "    # Convert boolean fields\n",
    "    bool_columns = ['verified', 'power_badge']\n",
    "    for col in bool_columns:\n",
    "        if col in users_df.columns:\n",
    "            users_df[col] = users_df[col].apply(str2bool)\n",
    "    \n",
    "    # Convert count fields to integers\n",
    "    count_columns = ['following_count', 'follower_count']\n",
    "    for col in count_columns:\n",
    "        if col in users_df.columns:\n",
    "            users_df[col] = pd.to_numeric(users_df[col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    logger.info(f\"Processed {len(users_df)} users\")\n",
    "    return users_df\n",
    "\n",
    "# Function to process a CSV file from S3\n",
    "def process_s3_file(url):\n",
    "    \"\"\"\n",
    "    Read a CSV file from S3, sanitize text fields, and convert data types.\n",
    "    \n",
    "    Args:\n",
    "        url: S3 URL for the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read CSV from S3 URL\n",
    "        df = pd.read_csv(url)\n",
    "        \n",
    "        # Sanitize text fields\n",
    "        text_columns = ['text', 'displayName', 'username', 'display_name', 'bio']\n",
    "        for col in text_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(sanitize_text)\n",
    "        \n",
    "        # Convert boolean fields\n",
    "        bool_columns = ['verified', 'power_badge']\n",
    "        for col in bool_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(str2bool)\n",
    "        \n",
    "        # Convert count fields to integers\n",
    "        count_columns = ['following_count', 'follower_count', 'followers_count']\n",
    "        for col in count_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing file {url}: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a Neo4j driver\n",
    "def get_neo4j_driver():\n",
    "    \"\"\"Get a Neo4j driver with connection details from environment variables\"\"\"\n",
    "    if not NEO4J_URI or not NEO4J_USERNAME or not NEO4J_PASSWORD:\n",
    "        logger.error(\"Neo4j connection details not found in environment variables\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error connecting to Neo4j: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to run a Neo4j query\n",
    "def run_neo4j_query(query, params=None):\n",
    "    \"\"\"Execute a Cypher query and return the results\"\"\"\n",
    "    driver = get_neo4j_driver()\n",
    "    if not driver:\n",
    "        return None\n",
    "        \n",
    "    session = None\n",
    "    response = None\n",
    "    try:\n",
    "        session = driver.session(database=NEO4J_DATABASE) if NEO4J_DATABASE else driver.session()\n",
    "        response = list(session.run(query, params))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Query failed: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if session:\n",
    "            session.close()\n",
    "        if driver:\n",
    "            driver.close()\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create or update Farcaster accounts in Neo4j\n",
    "def create_farcaster_accounts(url):\n",
    "    \"\"\"Create or update Farcaster accounts in Neo4j from CSV URL\"\"\"\n",
    "    logger.info(f\"Creating/updating Farcaster accounts from {url}\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{url}' AS row\n",
    "    \n",
    "    MERGE (account:Account:Farcaster {{fid: row.fid}})\n",
    "    ON CREATE SET \n",
    "        account.username = row.username,\n",
    "        account.displayName = row.display_name,\n",
    "        account.bioText = row.bio,\n",
    "        account.verified = row.verified,\n",
    "        account.powerBadge = row.power_badge,\n",
    "        account.followerCount = row.follower_count,\n",
    "        account.followingCount = row.following_count,\n",
    "        account.firstSeenAt = timestamp(),\n",
    "        account.lastUpdatedAt = timestamp()\n",
    "    ON MATCH SET \n",
    "        account.username = row.username,\n",
    "        account.displayName = row.display_name,\n",
    "        account.bioText = row.bio,\n",
    "        account.verified = row.verified,\n",
    "        account.powerBadge = row.power_badge,\n",
    "        account.followerCount = row.follower_count,\n",
    "        account.followingCount = row.following_count,\n",
    "        account.lastUpdatedAt = timestamp()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    result = run_neo4j_query(query)\n",
    "    \n",
    "    if result and result[0]:\n",
    "        count = result[0].get('accountCount', 0)\n",
    "        logger.info(f\"Created/updated {count} Farcaster accounts in Neo4j\")\n",
    "        return count\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:10:27,824 - __main__ - INFO - Found latest file: warpcast/users/20250328_073938_responses.json\n",
      "2025-03-28 15:10:58,004 - __main__ - INFO - Processing Warpcast account data\n",
      "2025-03-28 15:10:58,005 - __main__ - WARNING - Skipping unsuccessful batch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with 8671 batch responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:11:05,152 - __main__ - INFO - Processed 866901 users\n",
      "2025-03-28 15:11:05,657 - __main__ - INFO - Saving DataFrame with 866901 rows to S3 with prefix warpcast_accounts_1743199865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 866901 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:11:43,931 - __main__ - INFO - Successfully saved to https://census-warpcast-account-metadata.s3.amazonaws.com/warpcast_accounts_1743199865_1743199868.csv\n",
      "2025-03-28 15:11:43,965 - __main__ - INFO - Creating/updating Farcaster accounts from https://census-warpcast-account-metadata.s3.amazonaws.com/warpcast_accounts_1743199865_1743199868.csv\n"
     ]
    }
   ],
   "source": [
    "# Get latest Warpcast data file\n",
    "latest_file = get_latest_file('warpcast/users/')\n",
    "if not latest_file:\n",
    "    print(\"No files found in S3 bucket\")\n",
    "else:\n",
    "    # Get file content\n",
    "    content = get_file_content(latest_file)\n",
    "    if not content:\n",
    "        print(\"Failed to read file content\")\n",
    "    else:\n",
    "        # Parse JSON content\n",
    "        raw_data = json.loads(content)\n",
    "        print(f\"Loaded data with {len(raw_data)} batch responses\")\n",
    "        \n",
    "        # Process data into DataFrame\n",
    "        users_df = process_warpcast_data(raw_data)\n",
    "        print(f\"Processed {len(users_df)} users\")\n",
    "        \n",
    "        # Save to S3\n",
    "        timestamp = int(datetime.now().timestamp())\n",
    "        accounts_url = save_csv_to_s3(users_df, f\"warpcast_accounts_{timestamp}\")\n",
    "        \n",
    "        if accounts_url:\n",
    "            # Create accounts in Neo4j\n",
    "            count = create_farcaster_accounts(accounts_url)\n",
    "            print(f\"Created/updated {count} Farcaster accounts in Neo4j\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
